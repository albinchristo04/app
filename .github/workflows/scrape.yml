name: Scrape Daily Matches

on:
  workflow_dispatch:
  schedule:
    - cron: '0 1 * * *'

permissions:
  contents: write # Required to commit changes back to the repo if needed
  pages: write
  id-token: write
  actions: write # Required to upload artifacts

jobs:
  scrape-and-deploy:
    environment:
      name: github-pages
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.10'

      - name: Install Python dependencies
        run: |
          python -m pip install --upgrade pip
          pip install playwright
          playwright install chromium

      - name: Run DEBUG scraper to capture page state
        run: python scripts/scrape_yallashoot_to_json.py

      - name: Upload Debug Artifacts
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: debug-artifacts
          path: |
            debug_screenshot.png
            rendered_page.html
          if-no-files-found: ignore
          retention-days: 1 # Keep artifacts for 1 day

      # The following steps will likely fail or do nothing, which is OK for this debug run
      - name: Setup Pages
        uses: actions/configure-pages@v5
      
      - name: Upload artifact for deployment
        uses: actions/upload-pages-artifact@v3
        with:
          path: './matches'

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4