# scripts/pull_channels_and_update.py
# -*- coding: utf-8 -*-
"""
ÙŠØ³Ø­Ø¨ Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù‚Ù†ÙˆØ§Øª (TNT 1, TNT 2, Sky Sports Main Event UK, Sky Sports Premier League UK)
Ù…Ù† Ù…ØµØ¯Ø± M3U ÙˆÙŠØ­Ø¯Ø« premierleague.m3u Ø¨Ø§Ø³ØªØ¨Ø¯Ø§Ù„ **Ø³Ø·Ø± Ø§Ù„Ø±Ø§Ø¨Ø· ÙÙ‚Ø·** Ø§Ù„Ø°ÙŠ ÙŠÙ„ÙŠ #EXTINF
Ù„Ù†ÙØ³ Ø§Ù„Ù‚Ù†Ø§Ø©ØŒ Ø¨Ø¯ÙˆÙ† Ø£ÙŠ ØªØºÙŠÙŠØ± Ø¹Ù„Ù‰ Ù†Øµ Ø§Ù„Ù€EXTINF. Ù„Ø§ ÙŠØ¶ÙŠÙ Ù‚Ù†ÙˆØ§Øª Ø¬Ø¯ÙŠØ¯Ø©.

Ø¥ØµÙ„Ø§Ø­Ø§Øª Ù…Ù‡Ù…Ø©:
- Ù…Ø·Ø§Ø¨Ù‚Ø© Ù…Ø±Ù†Ø© Ù„Ù„Ø³ÙˆØ±Ø³ (Ø­ØªÙ‰ Ù„Ùˆ Ø§Ù„Ø§Ø³Ù… Ø¯Ø§Ø®Ù„ Ø¹Ù†ÙˆØ§Ù† Ø·ÙˆÙŠÙ„/Ø£Ù‚ÙˆØ§Ø³).
- Ù…Ø·Ø§Ø¨Ù‚Ø© ØµØ§Ø±Ù…Ø© Ù„Ù„Ø¯ÙŠØ³ØªÙ†ÙŠØ´Ù† Ø¹Ø¨Ø± regex Ù„Ù„Ù‚Ù†Ø§Ø© Ø¹Ù„Ù‰ Ø³Ø·Ø± Ø§Ù„Ù€EXTINF ÙÙ‚Ø·.
- Ù„ÙˆØ¬ ØªÙØµÙŠÙ„ÙŠ Ù„Ù…Ø¹Ø±ÙØ© Ø´Ù†Ùˆ Ø§Ù†Ù…Ø³Ùƒ ÙˆØªØ¨Ø¯Ù‘Ù„.
"""

import os
import re
import sys
import base64
from pathlib import Path
from typing import List, Tuple, Dict, Optional
import requests

# ===== Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª (Ø¨Ø¯ÙˆÙ† ØªØºÙŠÙŠØ± Ù…Ø¹Ù„Ù…Ø§ØªÙƒ) =====

SOURCE_URL = os.getenv(
    "SOURCE_URL",
    "https://raw.githubusercontent.com/pigzillaaa/daddylive/bc876b2f7935aeeb0df5b1c6b62b3c5f33998368/daddylive-channels-events.m3u8"
)

DEST_RAW_URL = os.getenv(
    "DEST_RAW_URL",
    "https://raw.githubusercontent.com/a7shk1/m3u-broadcast/refs/heads/main/premierleague.m3u"
)

GITHUB_TOKEN   = os.getenv("GITHUB_TOKEN", "").strip()
GITHUB_REPO    = os.getenv("GITHUB_REPO", "a7shk1/m3u-broadcast")
GITHUB_BRANCH  = os.getenv("GITHUB_BRANCH", "main")
DEST_REPO_PATH = os.getenv("DEST_REPO_PATH", "premierleague.m3u")
COMMIT_MESSAGE = os.getenv("COMMIT_MESSAGE", "ğŸ”„ auto-update premierleague.m3u (every 5min)")

OUTPUT_LOCAL_PATH = os.getenv("OUTPUT_LOCAL_PATH", "./out/premierleague.m3u")

TIMEOUT = 25
VERIFY_SSL = True

# ===== Ø§Ù„Ù‚Ù†ÙˆØ§Øª =====
WANTED_CHANNELS = [
    "TNT 1",
    "TNT 2",
    "Sky Sports Main Event UK",
    "Sky Sports Premier League UK",
]

# Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø³ÙˆØ±Ø³: Ù†Ø¨Ø­Ø« Ø¹Ù„Ù‰ **Ø³Ø·Ø± EXTINF ÙƒÙ„Ù‡** (Ø­ØªÙ‰ Ù„Ùˆ Ø§Ù„Ø§Ø³Ù… Ø¯Ø§Ø®Ù„ Ø§Ù„Ø¹Ù†ÙˆØ§Ù†/Ø§Ù„Ø£Ù‚ÙˆØ§Ø³)
SOURCE_PATTERNS: Dict[str, List[re.Pattern]] = {
    "TNT 1": [re.compile(r"\btnt\s*(sports)?\s*1\b", re.I)],
    "TNT 2": [re.compile(r"\btnt\s*(sports)?\s*2\b", re.I)],
    "Sky Sports Main Event UK": [
        re.compile(r"\bsky\s*sports\s*main\s*event\b", re.I),
        re.compile(r"\(.*sky\s*sports\s*main\s*event\s*(uk)?\).*", re.I),
    ],
    "Sky Sports Premier League UK": [
        re.compile(r"\bsky\s*sports\s*premier\s*league\b", re.I),
        re.compile(r"\(.*sky\s*sports\s*premier\s*league\s*(uk)?\).*", re.I),
    ],
}

# Ù…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„Ø¯ÙŠØ³ØªÙ†ÙŠØ´Ù†: **Ø³Ø·Ø± EXTINF ÙÙ‚Ø·**. Ù…Ø§Ù†ØºÙŠÙ‘Ø± Ù†ØµÙ‡ Ù†Ù‡Ø§Ø¦ÙŠÙ‹Ø§.
DEST_EXTINF_PATTERNS: Dict[str, re.Pattern] = {
    "TNT 1": re.compile(r"^#EXTINF[^,]*,\s*.*\btnt(\s*sports)?\s*1\b.*$", re.I),
    "TNT 2": re.compile(r"^#EXTINF[^,]*,\s*.*\btnt(\s*sports)?\s*2\b.*$", re.I),
    "Sky Sports Main Event UK": re.compile(
        r"^#EXTINF[^,]*,\s*.*\bsky\s*sports\s*main\s*event\b.*$", re.I
    ),
    "Sky Sports Premier League UK": re.compile(
        r"^#EXTINF[^,]*,\s*.*\bsky\s*sports\s*premier\s*league\b.*$", re.I
    ),
}

UK_MARKERS = (" uk", "(uk", "[uk", " united kingdom", "ğŸ‡¬ğŸ‡§")

# ===== ÙˆØ¸Ø§Ø¦Ù Ù…Ø³Ø§Ø¹Ø¯Ø© =====

def fetch_text(url: str) -> str:
    r = requests.get(url, timeout=TIMEOUT, verify=VERIFY_SSL)
    r.raise_for_status()
    return r.text

def parse_m3u_pairs(m3u_text: str) -> List[Tuple[str, Optional[str]]]:
    """[(extinf_line, url_or_None), ...]"""
    lines = [ln.rstrip("\n") for ln in m3u_text.splitlines()]
    out: List[Tuple[str, Optional[str]]] = []
    i = 0
    while i < len(lines):
        ln = lines[i].strip()
        if ln.startswith("#EXTINF"):
            url = None
            if i + 1 < len(lines):
                nxt = lines[i + 1].strip()
                if nxt and not nxt.startswith("#"):
                    url = nxt
            out.append((lines[i], url))
            i += 2
            continue
        i += 1
    return out

def source_match(extinf_line: str, target: str) -> bool:
    pats = SOURCE_PATTERNS.get(target, [])
    return any(p.search(extinf_line) for p in pats)

def pick_wanted(source_pairs: List[Tuple[str, Optional[str]]]) -> Dict[str, str]:
    """
    Ø§Ù„ØªÙ‚Ø· Ø£ÙØ¶Ù„ URL Ù…Ù† Ø§Ù„Ø³ÙˆØ±Ø³ Ù„ÙƒÙ„ Ù‚Ù†Ø§Ø© Ù…Ø·Ù„ÙˆØ¨Ø© (ØªÙØ¶ÙŠÙ„ UK/ğŸ‡¬ğŸ‡§ Ùˆ HD/FHD/UHD Ùˆ EN).
    """
    candidates: Dict[str, List[Tuple[str, str]]] = {name: [] for name in WANTED_CHANNELS}

    def has_uk_tag(s: str) -> bool:
        s_low = s.lower()
        return any(tag in s_low for tag in UK_MARKERS) or "ğŸ‡¬ğŸ‡§" in s

    for extinf, url in source_pairs:
        if not url:
            continue
        for name in WANTED_CHANNELS:
            if source_match(extinf, name):
                candidates[name].append((extinf, url))

    picked: Dict[str, str] = {}
    for name, lst in candidates.items():
        if not lst:
            continue

        def score(item: Tuple[str, str]) -> int:
            ext = item[0].lower()
            sc = 0
            if has_uk_tag(ext): sc += 5
            if any(q in ext for q in (" uhd", " 4k", " fhd", " hd")): sc += 2
            if re.search(r"\b(en|english)\b", ext): sc += 1
            return sc

        best = sorted(lst, key=score, reverse=True)[0]
        picked[name] = best[1]

    # Ù„ÙˆØ¬
    print("[i] Source candidates picked:")
    for n in WANTED_CHANNELS:
        print(f"  {'âœ“' if n in picked else 'x'} {n}")
    return picked

def update_dest_urls_only(dest_text: str, picked_urls: Dict[str, str]) -> Tuple[str, int]:
    """
    ÙŠÙ…Ø± Ø¹Ù„Ù‰ Ø§Ù„Ø¯ÙŠØ³ØªÙ†ÙŠØ´Ù† ÙˆÙŠØ¨Ø¯Ù‘Ù„ **Ø³Ø·Ø± Ø§Ù„Ø±Ø§Ø¨Ø· ÙÙ‚Ø·** Ø¨Ø¹Ø¯ ÙƒÙ„ EXTINF Ù…Ø·Ø§Ø¨Ù‚.
    ÙŠØ±Ø¬Ù‘Ø¹ (Ø§Ù„Ù†Øµ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØŒ Ø¹Ø¯Ø¯ Ø§Ù„ØªØ­Ø¯ÙŠØ«Ø§Øª).
    """
    lines = [ln.rstrip("\n") for ln in dest_text.splitlines()]
    if not lines or not lines[0].strip().upper().startswith("#EXTM3U"):
        lines = ["#EXTM3U"] + lines

    out: List[str] = []
    i = 0
    updates = 0

    while i < len(lines):
        ln = lines[i]
        if ln.strip().startswith("#EXTINF"):
            matched_name = None
            for name, pat in DEST_EXTINF_PATTERNS.items():
                if pat.search(ln):
                    matched_name = name
                    break

            if matched_name and matched_name in picked_urls:
                # Ø¥Ø¨Ù‚ÙŠ Ø§Ù„Ù€EXTINF ÙƒÙ…Ø§ Ù‡Ùˆ
                out.append(ln)
                new_url = picked_urls[matched_name]

                # Ø¥Ø°Ø§ Ø§Ù„Ø³Ø·Ø± Ø§Ù„Ø¨Ø¹Ø¯Ù‡ URL (Ù…Ùˆ ØªØ¹Ù„ÙŠÙ‚): Ø¨Ø¯Ù‘Ù„Ù‡ØŒ ÙˆØ¥Ù„Ø§ Ø£Ø¯Ø±Ø¬Ù‡
                if i + 1 < len(lines) and lines[i + 1].strip() and not lines[i + 1].strip().startswith("#"):
                    old_url = lines[i + 1]
                    if old_url != new_url:
                        updates += 1
                        print(f"[i] Updated URL for: {matched_name}")
                    else:
                        print(f"[i] URL already up-to-date: {matched_name}")
                    out.append(new_url)
                    i += 2
                    continue
                else:
                    updates += 1
                    print(f"[i] Inserted URL for: {matched_name}")
                    out.append(new_url)
                    i += 1
                    continue

        out.append(ln)
        i += 1

    return ("\n".join(out).rstrip() + "\n", updates)

def upsert_github_file(repo: str, branch: str, path_in_repo: str, content_bytes: bytes, message: str, token: str):
    base = "https://api.github.com"
    url = f"{base}/repos/{repo}/contents/{path_in_repo}"
    headers = {"Authorization": f"Bearer {token}", "Accept": "application/vnd.github+json"}

    sha = None
    get_res = requests.get(url, headers=headers, params={"ref": branch}, timeout=TIMEOUT)
    if get_res.status_code == 200:
        sha = get_res.json().get("sha")

    payload = {
        "message": message,
        "content": base64.b64encode(content_bytes).decode("utf-8"),
        "branch": branch,
    }
    if sha:
        payload["sha"] = sha

    put_res = requests.put(url, headers=headers, json=payload, timeout=TIMEOUT)
    if put_res.status_code not in (200, 201):
        raise RuntimeError(f"GitHub PUT failed: {put_res.status_code} {put_res.text}")
    return put_res.json()

def main():
    # 1) Ø­Ù…Ù‘Ù„ Ø§Ù„Ù…ØµØ¯Ø± ÙˆØ§Ù„ÙˆØ¬Ù‡Ø©
    src_text = fetch_text(SOURCE_URL)
    dest_text = fetch_text(DEST_RAW_URL)

    # 2) Ø§Ø®ØªÙØ± Ø£ÙØ¶Ù„ Ø±ÙˆØ§Ø¨Ø· Ù…Ù† Ø§Ù„Ø³ÙˆØ±Ø³
    pairs = parse_m3u_pairs(src_text)
    picked_urls = pick_wanted(pairs)

    # 3) Ø­Ø¯Ù‘Ø« Ø§Ù„Ø¯ÙŠØ³ØªÙ†ÙŠØ´Ù† (Ø³Ø·Ø± URL ÙÙ‚Ø·)
    updated_text, updates = update_dest_urls_only(dest_text, picked_urls)

    # 4) Ø§ÙƒØªØ¨ Ø¥Ù„Ù‰ GitHub Ø£Ùˆ Ù…Ø­Ù„ÙŠÙ‹Ø§
    if updates == 0:
        print("[i] No changes to write.")
        # Ø­ØªÙ‰ Ù„Ùˆ Ù…Ø§ÙƒÙˆ ØªØºÙŠÙŠØ±ØŒ Ù†ÙƒØªØ¨ Ù…Ø­Ù„ÙŠÙ‹Ø§ Ø¥Ø°Ø§ Ù…Ø§ÙƒÙˆ ØªÙˆÙƒÙ† (Ù„Ù„ØªØ­Ù‚Ù‚)
    token = GITHUB_TOKEN
    if token:
        print(f"[i] Writing to GitHub: {GITHUB_REPO}@{GITHUB_BRANCH}:{DEST_REPO_PATH}")
        res = upsert_github_file(
            repo=GITHUB_REPO,
            branch=GITHUB_BRANCH,
            path_in_repo=DEST_REPO_PATH,
            content_bytes=updated_text.encode("utf-8"),
            message=COMMIT_MESSAGE,
            token=token,
        )
        print("[âœ“] Updated:", res.get("content", {}).get("path"))
    else:
        p = Path(OUTPUT_LOCAL_PATH)
        p.parent.mkdir(parents=True, exist_ok=True)
        p.write_text(updated_text, encoding="utf-8")
        print("[i] Wrote locally to:", p.resolve())

if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        print("[x] Error:", e)
        sys.exit(1)
